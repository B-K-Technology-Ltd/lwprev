{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to LightWare's Developer Portal where we will walk you through how to integrate our lidar sensors into real-world scenarios, hoping this will accelerate your journey towards a production ready solution.</p> <p>Here are the current scenario we cover:</p> <ol> <li> <p>Landing on a Moving Platform</p> <p>This scenario covers how you can leverage several LW20/C sensors to create a real time understanding of a ground plane to make a decision to land.  This type of motion handling is typical - but not exclusive - to moving platform and is a capability that is expected for drone solutions to enter new markets.</p> </li> <li> <p>Precision Positioning</p> <p>This scenario covers how you can leverage a SF30/D sensor to get a precise and real time read of a distance between the vehicle and an object of interest. This capability become critical for scalability automation that allows for accurate data collection on a large range of data collecting and real-world interacting payloads.</p> <p>For instance, if you use a radiation detector and need to operate at a fixed 50cm distance, this capability is mandatory.</p> </li> </ol>"},{"location":"#other-resources","title":"Other Resources","text":"<p>If you would to continue your journey with our products, we invite you to explore these additional resources:</p> <ul> <li>Resource Center - Where you will find all manual, CAD files, API/documentations, etc</li> <li>Github Repository - Where you can find sample codes and libraries</li> <li>Contact Page - Where you can reach out to our teams to get support in your integration of our products</li> <li>Main Website - Where you can find all products, their details and all other information about LightWare Lidars.</li> </ul>"},{"location":"landing-moving-platform/","title":"M350 Landing on a Moving Platform","text":"<p>In this scenario, we are going to walk through the steps to add a capability to the DJI M350 which isn't present on the vehicle by default: The ability to land on a moving platform.</p> <p>Such platform can be a ground, aerial or a marine vehicle.  We will focus on the marine context to set the scene, because its application is more grounded.  Even a stopped vessel will still experience movements, so it is up to the drone to be able to handle it.</p> <p>Specifically, let's assume we are in the context of an inspection.</p> <p></p> <p>As you can see, the boat will be subjected to the movement of the water.  This will force its deck to be moving along three translation and three rotation axis. For a safe landing, an undamaged and reusable drone, we need to achieve a clean landing.</p> <p>This means we need to understand the condition of the boat landing pad, take a decision and execute the landing.</p> <p>We will go through all the details in the plan part of this tutorial.</p> <p>Note</p> <p>As the scope of this tutorial is to focus on how to use our products, we will skim through the other components and only cover the extent necessary for the whole solution to be reproducible and extendable. We will provide insight on how to explore this further and productize it, should this be something you would like to pursue.</p>"},{"location":"landing-moving-platform/components/","title":"Components","text":"<p>Let's go over the components for this solution and more importantly, cover why these would be leveraged, and where improvements are possible.</p>"},{"location":"landing-moving-platform/components/#parts-list","title":"Parts List","text":"Image Component Role Quantity DJI M350 Main Vehicle 1 LW20/C Landing Deck Plane Detection 4 Raspberry Pi 5 + SD Card Onboard Compute 1 Raspberry Pi 5 Cooling Kit Cooling for Onboard Compute  Note: This is not strictly necessary for this exercise, but future proofs the setup. 1 DJI E-Port Kit Payload SDK Interface 1 5A/5V Voltage Regulator Voltage regulator for the Pi 5 which requires 5V/5A while the E-Port 5V rail is limited to 2A 1 I2C Breakout Board Ad-hoc I2C bus hardware for all the sensors 1 USB to TTL Cable Connect the UART from the devkit to the Pi 1 LW20C Mounting Brackets Holding the LW20/C against the rails 4 Lidar Mounting Rails Holding the LW20/C in an array configuration 2 Compute and E-Port Mounting Kit Holding the E-Port and the Raspberry pi in place 1 Voltage Regulator/I2C Bus Mount Holding the Voltage Regulator and the I2C Bus breakout in place 1 XT30 Power Cables Provide power to the voltage regulator. Note: You can make these yourself if you feel up to it. This example uses 16AWG which is much more than needed. 1 Female Dupont Cables Power from voltage regulator to Pi and I2C wiring between Pi and Bus breakout. Note: You can make these yourself if you feel up to it - We're going to crimp the LW20 cables anyway. It's also quite convenient to buy ready made cable and cut/strip them to your need 6 M1.6 x 8mm Counter Sunk Screws Secure the clips to the rails 12 (4x3) M2.5 x 4mm Heat-set Insert Allows to attach he voltage regulator and easily remove/reinstall 4 M3 x 4mm Heat-set Insert Allows to attach he voltage regulator and easily remove/reinstall 4 M2.5 x 6mm Screws Secure the Raspberry Pi to the Mount 4 M3 x 6mm Screws Secure the Voltage Regulator and the I2C Breakout to the Mount 6 M3x8mm Standoffs Used to elevate the voltage regulator and the I2C breakout 6 M3 x 8mm Screws Secure the Back Compute/E-port Mount &amp; Back of the rails to the Vehicle 4 M3 x 10mm Screws Secure Front of the rails to the Vehicle 2 M3 x 15mm Screws Secure the Front Compute/E-port Mount 2 Zip Ties - 6 inch Secure Cables to Lidar Rails and top mount 3-5 BluTack Secure the EPort and Cables to the vehicle 1 Dupont Female headers + Crimper Simple connection of the LW20/C to the Raspberry Pi 1 28AWG silicon wire kit Misc. Wiring 1"},{"location":"landing-moving-platform/components/#dji-m350","title":"DJI M350","text":"<p>It's a good PayloadSDK enabled Aircraft with a great track record of being a workhorse with inspections - including a great range of top of the line payloads.</p>"},{"location":"landing-moving-platform/components/#lw20c","title":"LW20/C","text":"<p>We chose the LW20 for its range and its small form factor.  It's tempting to look at a multi-point lidar (like a 3D lidar), but it's not really necessary and the form factors would be significantly impacting the vehicle performance and time in the air.</p> <p>By choosing a small lidar unit and leveraging software, we create a lightweight, yet powerful solution which gives us everything we need.</p>"},{"location":"landing-moving-platform/components/#raspberry-pi-5-e-port-kit","title":"Raspberry Pi 5 + E-Port Kit","text":"<p>Chosen for its compute capabilities and its wide availability, the Raspberry Pi 5 is a good mid-size computer that's instantaneously available.  There are many other choices that can navigate the range of solutions from lower power at smaller footprint or higher power as a bigger footprint.</p> <p>For the focused context of this scenario, this is plentiful.</p> <p>The E-Port Kit is a simple solution which is also widely available and affordable. </p> <p>Note</p> <p>Neither are particularly elegant solution that will make the end result feel like a real product and the natural next step  would be developing a custom compute/E-Port breakout board in a clean package - which is not particularly difficult to achieve once the product capabilities has been validated.</p>"},{"location":"landing-moving-platform/components/#mounting-hardware","title":"Mounting Hardware","text":"<p>We chose to mount the LW20/C in a location that can allow for its placement to be both delivering on its expectations and remain out of the way of other critical components.</p> <p>All the parts are chosen to be modular, leveraging our mounting bracket which you can easily acquire from our store, or print yourself using our CAD files available in our resource center</p> <p>Now that we have all the parts involved, we can move onto putting the kit together.</p>"},{"location":"landing-moving-platform/conclusion/","title":"Conclusion","text":"<p>As we got over all aspects of getting a LightWare based project, we want to leave you with the right level of understanding of the high level pictures of such projects.</p> <p>We hope we have demystified the hardware aspect by simplifying the access to all components, so you can get into the software space as quickly as possible.</p> <p>We hope you see that the software is incredibly simple to get results yet has virtually no end to the sophistication and the value you can create with our sensors.</p> <p>We hope this has inspired you to think about how our products can unlock the next generation of advanced robotic behavior with drones but also with any other platforms.</p> <p>Regardless, feel free to continue reading as we cover other scenarios on this portal.</p>"},{"location":"landing-moving-platform/hardware/","title":"Hardware","text":"<p>Let's put the hardware together.</p> <p>Before you begin, make sure you have all the parts from the previous section.</p>"},{"location":"landing-moving-platform/hardware/#sensors","title":"Sensors","text":""},{"location":"landing-moving-platform/hardware/#preparation","title":"Preparation","text":"<p>First, we are going to prepare the rails and the clips that will attach the sensors on the belly of the aircraft.</p> <p>Secure the clips using the counter sunk screws as shown in this picture:</p> <p></p> <p>Next, we need to prepare the termination of the sensor to use dupont connectors. Out of the package, you will notice that the LW20/c comes with free wires. This is to give you options as to how to integrate, but in this case, we are going to use dupont connectors for convenience.</p> <p></p> <p>Crimp the black (<code>GND</code>), red (<code>VCC</code>), white (<code>RX/SCL</code>) and yellow (<code>TX/SDA</code>) wires individually, then encase them in a connector in this order.</p> <p></p>"},{"location":"landing-moving-platform/hardware/#mounting","title":"Mounting","text":"<p>Let's start by attaching the 3D printed bracket under the M350. </p> <p>Flip the aircraft on its 'head' (this is why we do this now, because the computer will be there once we are done). Remove and save the payload screws in case you want to remove the kit later.</p> <p></p> <p>Secure both rails using the M3x10mm on the front (where the payload is) and the M3x8mm for the back.</p> <p></p> <p>Clip the sensor to the printed parts and use blutack (it may be a different color in your country) to hold the cables close to the body of the aircraft.</p> <p> </p> <p>Note</p> <p>There are obviously more resilient ways to secure the cables for production deployment, but our approach here is of R&amp;D and quick validation of the end-to-end system.</p> <p>You may choose to pass the cables and zip tie it all. The rails are ready for this, but you may need to extend the length of the wires for the back sensors.</p> <p>Otherwise, you can simply guide and putty the cables along the side of the aircraft while making sure not to block the view of the obstacle avoidance sensors.</p> <p>Once you have secured all four sensors, you are ready to move to the next step.</p>"},{"location":"landing-moving-platform/hardware/#compute-unit","title":"Compute Unit","text":"<p>Next, we are going to look at mounting the compute unit on the top of the aircraft.</p>"},{"location":"landing-moving-platform/hardware/#preparations","title":"Preparations","text":"<p>First, we will use the M2.5 heat-set inserts for the Raspberry Pi posts on the compute mount.  To insert them, simply use a soldering iron at the melting temperature of the plastic you use for printing the model. Pull out when sufficiently inserted.</p> <p>Note</p> <p>The heat-set inserts are an optional improvements. If you want to skip them, you can simply use coarse screws - such as wood screws - into the plastic directly.</p> <p></p> <p>Next, we will prepare the additional board for the voltage regulator that will provide the bulk of the power to the Raspberry Pi and the I2C breakout board.</p> <p>Note</p> <p>You can choose other options for the I2C bus and the voltage regulator as long as you provide what's necessary for the pi to work.</p> <p>First, we place the heat-set inserts as done before.</p> <p></p> <p>Next we are going to prepare the power cables. If you've opted to the ready made cables, you can skip this. If you want to make your own:</p> <p>Cut two set of black and red pairs of the 20AWG silicon cable: 12cm or 4 3/4\" for the power to the Pi; 16cm of 6 1/4\" for the power from the E-port Dev Kit.</p> <p>The Pi cable (12cm) will be crimped and set in a two line dupont connector</p> <p></p> <p>The E-Port Dev Kit will be soldered to an XT30 connector.</p> <p></p>"},{"location":"landing-moving-platform/hardware/#mounting_1","title":"Mounting","text":""},{"location":"landing-moving-platform/hardware/#raspberry-pie-port","title":"Raspberry Pi/E-Port","text":"<p>Grab the top mount and let's start with the E-Port Kit. It will sit in the bottom, under the Raspberry Pi. Place the E-Port kit as seen on the picture below, making sure that it sits in between the securing post.</p> <p></p> <p>Note</p> <p>You can secure it with zip ties or bluetac. The putty will do a great work, while the Raspberry Pi posts will prevent it to fly away in case of failure.</p> <p>Also, note the orientation as it will matter greatly. The \"Drone\" USB-C port should be facing starboard side of the mount.</p> <p>Verify that it isn't moving before moving to the next step.</p> <p>Before we move to the Pi, now is a good time to connect the USB/TTL cable to the pins on the E-Port as you'll be able to see the markings on the PCB.</p> <p>You can also plug in the USB-C cable that came with the kit, making sure the B side is showing upwards.</p> <p></p> <p>Note</p> <p>The USB-C cable used for DJI development aren't regular USB-C cable. They aren't reversable. This is why they are noted with a A side and a B side. Pay close attention to the orientation as described in the DJI developer documentation:  </p> <p>Don't plug to the aircraft just yet.</p> <p>Time to attach the Raspberry Pi. You can choose to bring it with a case if you choose, but the mount we offer is coming with a through hole installation that's only compatible with the naked board or using the official case. Regardless, using the M2.5x6mm screws, secure the raspberry pi with the connectors facing the back of the aircraft.</p> <p>Don't over tighten.</p> <p></p>"},{"location":"landing-moving-platform/hardware/#voltage-regulator-and-i2c-breakout","title":"Voltage Regulator and I2C Breakout","text":"<p>To finish the add-on board, use the M3x6mm screws to secure the voltage regulator and the I2C bus breakout to the side board.</p> <p></p> <p>Next, connect to the input terminals the E-Port power cable and the Pi power cable to the output.</p> <p></p> <p>Note</p> <p>We will set up the voltage converter soon, but for now do not power anything.</p> <p>At this point the side board is fully assembled.</p>"},{"location":"landing-moving-platform/hardware/#assembly","title":"Assembly","text":"<p>First, we need to prepare the SDCard for the Raspberry Pi. Follow these instructions to get it done</p> <p>Once finished, place the SD Card in the Pi's slot.</p> <p>Next, clip the side board to the front of the Pi's mount. </p> <p></p> <p>Note</p> <p>The round clip would be enough to secure it, but if you want, you can secure them further with zip ties.</p> <p>Connect the XT30 power cable to the E-Port Dev Kit's unregulated power connector.</p> <p></p> <p>Connect the short USB-C cable between the device USB port of the E-Port dev kit and the Raspberry Pi's - This will be our fast data line.</p> <p></p> <p>Coil the USB to TTL cable around the base of the mount and connect the USB-A connector to one of the Raspberry Pi's. You can also zip tie it against the frame.</p> <p></p> <p>You should have something looking like this:</p> <p>Note</p> <p> Wiring diagram from DJI's Developer Documentation</p> <p>Now we can connect the I2C pins to the bus and to the Raspberry Pi.</p> <p>Using the Dupont cables, connect each of the I2C lines to the Raspberry Pi pins. </p> <p>Save the pin 4 &amp; 6 for the power input out of the voltage regulator.</p> <p>Warning</p> <p> <p>Pinout from pinout.xyz</p> <p></p> <p>At this point, the only unconnected cable should be the power cable output of the voltage regulator. We will plug it after we configured the regulator with the aircraft power.</p>"},{"location":"landing-moving-platform/hardware/#aircraft-installation","title":"Aircraft Installation","text":"<p>First, we mount the completed kit to the aircraft using the M3x8mm screws in the back and the M3x15mm in the front.</p> <p></p> <p>With the dev kit secured, it's time to connect the usb cable to the aircraft.</p> <p>Note</p> <p>As mentioned before, the USB-C cable used for DJI development aren't regular USB-C cable. They aren't reversable. This is why they are noted with a A side and a B side. Pay close attention to the orientation as described in the DJI developer documentation:  </p> <p>From this point onwards, the kit will be powered when the aircraft is on and able to break-out the data connection to the vehicle, but the Raspberry Pi won't be able to get all the power it wants.</p>"},{"location":"landing-moving-platform/hardware/#configurations","title":"Configurations","text":"<p>First, let's make sure the switches on the E-Port Dev Kit are switch correctly.</p> <p>By the drone USB-C side, make sure it's switch to on.</p> <p>By the payload USB-C side, make sure it's on host mode.</p> <p>Next, let's adjust the voltage regulator. The voltage regulator we chose is based on the XL4015 chip. The voltage is adjusted by working the potention-meter for the voltage limitations. In doubt, check markings on the PCB.</p> <p>Power on the aircraft, and confirm the voltage regulator is being powered on. The model we selected comes with a digital display and LEDs for that purpose.</p> <p>Warning</p> <p>If you use the same voltage regulator, the screen is only informational in nature. The modes to cycle won't change the output voltage.</p> <p>While powered on, use a multimeter on the output terminal to measure the output voltage. Turn the voltage limiting potentiometer until you reach 5V.</p> <p>Note</p> <p>It's not a bad idea now to leave the display to show the output current or power.</p> <p></p>"},{"location":"landing-moving-platform/hardware/#last-steps","title":"Last Steps","text":"<p>Power off the aircraft before continuing.</p> <p>Connect the output power lead to the power pins of the raspberry pi. Check the pin out above or the picture below.</p> <p></p> <p>And finally, the sensor lines to the I2C bus.</p> <p></p>"},{"location":"landing-moving-platform/hardware/#tidying-up","title":"Tidying Up","text":"<p>As a final step, attach all loose cables with zip ties. Make sure the kit is still as removable as possible for future maintenance and desk development.</p> <p></p>"},{"location":"landing-moving-platform/plan/","title":"Plan","text":"<p>In order to land a vehicle on a moving platform, we need to first characterize the situation. </p> <p>As we covered before, the deck of the boat will be moving in six degrees of freedom (three translation, three rotation) - even if some are less affected. All this motion will limit the window of opportunity for the vehicle to commit to a landing.</p> <p>To understand when the window of opportunity presents itself, we need to be able to observe in real time the plane represented by the deck, identify a moment of least-risk and commit with understanding of the motion capabilities of the vehicle and the structural strength of the drone.</p> <p></p> <p>The DJI M350 does have sensor packages all around itself, but most aren't accessible to developers. Fortunately, the PayloadSDK allows us to bring our sensors and our computer onboard. With these we can also bring our control logic and write a custom landing mode.</p> <p>So we can create an array of our LW20 lidar sensor to create an accurate reading of the distance to the ground, recreate the plane it represents, process it on an onboard computer, make our decision and execute the landing using the PayloadSDK.</p> <p>We will use custom-made hardware to secure the sensors and the computer onto the drone, with off-the-shelves components as to make this all the more accessible.</p> <p></p> <p>Now that we have a decent idea of how we can approach the problem, let's go over the components choice in details.</p>"},{"location":"landing-moving-platform/software/","title":"Software","text":""},{"location":"landing-moving-platform/software/#configuration","title":"Configuration","text":"<p>Before we dive into the code for the application, we need to set up all the baseline components</p>"},{"location":"landing-moving-platform/software/#payload-sdk-raspberry-pi","title":"Payload SDK &amp; Raspberry Pi","text":"<p>DJI covers really well how to get the Raspberry Pi setup, so follow the set up steps here</p> <p>Once you can run the sample code, we can move to the next step.</p> <p>Make sure to configure the Raspberry Pi to connect to your local Wi-Fi if available.</p> <p>Also, for convenience, make sure you have set up SSH access.</p> <p>While you are in the <code>Raspberry Pi Configuration</code> screen (from the top left menu), turn on \"I2C\"</p>"},{"location":"landing-moving-platform/software/#lw20c","title":"LW20/C","text":"<p>Each LW20/c comes configured with <code>0x66</code> as a I2C address, so we need to assign a new one to each device.</p> <p>To do so, you can use the LightWare Studio App.  Download the app, connect the sensor to a FTDI cable (the same type from the kit) and follow the instructions from the user manual.</p> <p>We want to have a dedicated address for each, so let's use <code>0x66</code>, <code>0x67</code>, <code>0x68</code>, <code>0x69</code>. You'll notice that in LightWare Studio, the value are in decimal. Simply increase by 1.</p> <p>Note</p> <p>Mark the address on each sensor as their positioning on the aircaft will matter for future logics.</p> <p>Reconnect all the sensors to the pi, and let's confirm that we can see them.</p> <p>On the pi, if you don't have them (unlikely scenario), install the i2c tooling: <pre><code>sudo apt-get install i2c-tools\n</code></pre></p> <p>Then, verify you can see the sensors using:</p> <pre><code>i2cdetect -y 1\n</code></pre> <p>You should see something like this:</p> <pre><code>     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f\n00:                         -- -- -- -- -- -- -- -- \n10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n60: -- -- -- -- -- -- 66 67 68 69 -- -- -- -- -- -- \n70: -- -- -- -- -- -- -- --  \n</code></pre> <p>You are now ready to dive into the code.</p>"},{"location":"landing-moving-platform/software/#project-code","title":"Project Code","text":"<p>Tip</p> <p>All the code for we are going to go over is available here.</p> <p>The code is in itself, functionally simple. We started by writing several classes that will abstract the sensor, the array of them and the vehicle interaction. For the vehicle and to remain true to the content set by DJI, we used the same <code>Application</code> class from their sample code.</p> <p>Note</p> <p>Remember that this project isn't production ready. If you want to deliver this functionality you'll have to finish parts of the work.</p>"},{"location":"landing-moving-platform/software/#connecting-to-the-aircraft","title":"Connecting to the Aircraft","text":"<p>Because the Payload SDK does the work for us, once we are set up with the hardware, the work becomes as simple as this:</p> <pre><code>Application *vehicle = NULL;\n\nint main(int argc, char **argv) {\n    // Create the vehicle instance to connect\n    // We are reusing the Application object from DJI's sample for clarity only.\n    vehicle = new Application(argc, argv);\n</code></pre> <p>From this point on, the vehicle object can be used to abstract vehicle functions. </p> <p>Note</p> <p>The Payload SDK uses functions. These would be accessible in the global space, but structure with objects is a neater way to organize functions.</p>"},{"location":"landing-moving-platform/software/#connection-to-the-lw20c","title":"Connection to the LW20/c","text":"<p>Following the logic of abstraction, we are going to create two objects: <code>LW20</code> and <code>SensorArray</code>.</p> <p><code>LW20</code> is used to abstract a single sensor. This includes all controls and reads.</p> <p><code>SensorArray</code> is specific to this project and abstracts the four sensors in their physical configuration.</p> <p>Note</p> <p>A lot more effort can be put in these abstractions should the need come to expand on the current approach.  These classes are great places to contain it.</p> <p>First, we bring in all the headers needed for future work and then declare the class:</p> <pre><code>//\n// Created by LightWare.\n// LW20/c Interface\n//\n\n#pragma once\n\n#include &lt;iostream&gt;\n\n#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n#include &lt;sys/ioctl.h&gt;\n#include &lt;asm/ioctl.h&gt;\n\n#include &lt;fcntl.h&gt;\n#include &lt;string.h&gt;\n\nclass LW20 {\n</code></pre> <p>Then we define a <code>ioctl</code> configuration macro. This is necessary because we work on a Raspberry Pi 5 and the wiringPi which handles these variations isn't available.</p> <pre><code>#define I2C_SLAVE   0x0703\n</code></pre> <p>Next, we can implement the public interface which manages the life cycle of the abstraction and protected access to private information:</p> <pre><code>public:\n    LW20() {\n\n    }\n\n    ~LW20() {\n        this-&gt;disconnect();\n    }\n\n    void connect(int i2cAddress) {\n        _deviceAddress = i2cAddress;\n\n        const char *device = \"/dev/i2c-1\"; // This may change, wiringPi has a good discovery for this, but it's not available yet on pi5.\n        _fd = open (device, O_RDWR);\n\n        if (_fd == -1) {\n            std::cerr &lt;&lt; \"I2C Bus file could not be opened\" &lt;&lt; std::endl;\n        } else {\n            std::cerr &lt;&lt; \"I2C Bus opened on FD: \" &lt;&lt; _fd &lt;&lt; std::endl;\n\n            if (ioctl (_fd, I2C_SLAVE, i2cAddress) &lt; 0) {\n                std::cerr &lt;&lt; \"Unable to select I2C device: \" &lt;&lt; strerror(errno) &lt;&lt; std::endl;\n            } else {\n                _threadRunning.store(true, std::memory_order_relaxed);\n                _runningThread = std::thread(&amp;LW20::loop, this);\n            }\n        }\n    }\n\n    void disconnect() {\n        _threadRunning.store(false, std::memory_order_relaxed);\n        close(_fd);\n    }\n\n    int latestDistance() {\n        return this-&gt;_latestDistance.load(std::memory_order_relaxed);\n    }\n</code></pre> <p>Last, we do the private implementation which covers the internal loop running in a background thread to read the data from the sensor and the protected variables.</p> <pre><code>private:\n    std::atomic&lt;bool&gt; _threadRunning{false};\n    std::thread _runningThread;\n\n    int _deviceAddress = 0x66; // default factory value\n    int _fd;\n\n    std::atomic&lt;int&gt; _latestDistance{0}; // in cm\n\n    // Loop running in background thread.\n    void loop() {\n        while (_threadRunning.load(std::memory_order_relaxed))  {\n            unsigned char byte[2];\n            int res = read(_fd, byte, 2);\n\n            if (res == -1) {\n                std::cout &lt;&lt; \"I2C Device with address \" &lt;&lt; _deviceAddress &lt;&lt; \" was not available\" &lt;&lt; std::endl;\n            } else {\n                int distanceRead = (byte[0] &lt;&lt; 8) | byte[1];\n                std::cout &lt;&lt; \"[\" &lt;&lt; _deviceAddress &lt;&lt; \"] Distance: \" &lt;&lt; distanceRead &lt;&lt; \"cm\" &lt;&lt; std::endl;\n\n                _latestDistance.store(distanceRead, std::memory_order_relaxed);\n            }\n\n            usleep(250);\n        }\n    }\n};\n</code></pre> <p>Note</p> <p>The way this class is set, the address is defined during the connect function.  You could just as easily set it at allocation and have a parameter-less connect function. This is just a matter of preference.</p> <p>Now that we have a single sensor implementation sorted, we need to move onto the <code>SensorArray</code></p> <p>Again, this object is a convenience luxury which makes the main business logic really light and abstracted behind trusted classes.</p> <p>As before, we start with the header call we will need and class declaration.</p> <pre><code>//\n// Created by LightWare.\n// Software representation of the LW20/c quad sensor array for platform detection\n//\n\n#pragma once\n\n#include \"LW20.h\"\n#include &lt;limits&gt;\n\nclass SensorArray {\n</code></pre> <p>The public interface handles the life cycle of the sensors:</p> <pre><code>public:\n    SensorArray() {\n        this-&gt;_sensor1 = new LW20();\n        this-&gt;_sensor2 = new LW20();\n        this-&gt;_sensor3 = new LW20();\n        this-&gt;_sensor4 = new LW20();\n    }\n\n    ~SensorArray() {\n        delete this-&gt;_sensor1;\n        delete this-&gt;_sensor2;\n        delete this-&gt;_sensor3;\n        delete this-&gt;_sensor4;\n    }\n\n    // Connects the entire array and start receiving distances\n    void connect() {\n        this-&gt;_sensor1-&gt;connect(0x66);\n        this-&gt;_sensor2-&gt;connect(0x67);\n        this-&gt;_sensor3-&gt;connect(0x68);\n        this-&gt;_sensor4-&gt;connect(0x69);\n    }\n\n    // Average distance in cm\n    int averageDistance() {\n        int sensor1LastRead = this-&gt;_sensor1-&gt;latestDistance();\n        int sensor2LastRead = this-&gt;_sensor2-&gt;latestDistance();\n        int sensor3LastRead = this-&gt;_sensor3-&gt;latestDistance();\n        int sensor4LastRead = this-&gt;_sensor4-&gt;latestDistance();\n\n        return (sensor1LastRead + sensor2LastRead + sensor3LastRead + sensor4LastRead)/4;\n    }\n\n    // Return the maximum differences between the closest and the furthest away hit\n    int maxDelta() {\n        int sensor1LastRead = this-&gt;_sensor1-&gt;latestDistance();\n        int sensor2LastRead = this-&gt;_sensor2-&gt;latestDistance();\n        int sensor3LastRead = this-&gt;_sensor3-&gt;latestDistance();\n        int sensor4LastRead = this-&gt;_sensor4-&gt;latestDistance();\n\n        int distances[4] = {sensor1LastRead, sensor2LastRead, sensor3LastRead, sensor4LastRead};\n        int lowest = std::numeric_limits&lt;int&gt;::max();\n        int highest = std::numeric_limits&lt;int&gt;::min();\n\n        for(int i = 0; i &lt; size; ++i) {\n            if(distances[i] &lt; lowest) {\n                lowest = distances[i];\n            }\n            if(distances[i] &gt; highest) {\n                highest = distances[i];\n            }\n        }\n\n        return highest - lowest;\n    }\n</code></pre> <p>Private interfaces aren't doing much except holding onto the sensor pointers.</p> <pre><code>private:\n    LW20 *_sensor1;\n    LW20 *_sensor2;\n    LW20 *_sensor3;\n    LW20 *_sensor4;\n\n};\n</code></pre> <p>Now that we have an abstraction for the vehicle and the sensor array, it's time to tie it all up together.</p>"},{"location":"landing-moving-platform/software/#plane-detection-logic","title":"Plane Detection Logic","text":"<p>As the purpose of this tutorial is to cover how to leverage the sensors, we are taking the most simplistic approach to solving this problem.  This means there is obviously a lot of room for improvements towards delivering a resilient and production ready solution. We will cover a few next steps should you want to take it further after we covered the simple solution we offer.</p> <p>Back to the <code>main.cpp</code> file in the <code>main</code> function, after we created the abstraction for the vehicle, we create the abstraction for the sensor array and connect it.</p> <p>After this, we assume we are in checking to land logic. We loop until the condition met is hit, then we exit the loop and trigger the landing:</p> <pre><code>int main(int argc, char **argv) {\n    // Create the vehicle instance to connect\n    // We are reusing the Application object from DJI's sample for clarity only.\n    vehicle = new Application(argc, argv);\n\n    sensorArray = new SensorArray();\n    sensorArray-&gt;connect();\n\n    // Check loop\n    bool checkingToLand = true;\n    int flatEnough = 10; // in cm; 10cm -&gt; ~15\u00b0 plane\n\n    while (checkingToLand) {\n        int maxDelta = sensorArray-&gt;maxDelta();\n\n        // Condition to determine a landing opportunity.\n        if (maxDelta &lt;= flatEnough &amp;&amp; maxDelta &gt; 0) {\n            checkingToLand = false;\n            break;\n        }\n    }\n</code></pre> <p>As you can see this is incredibly simple in this form so here are extra next steps for your consideration:</p>"},{"location":"landing-moving-platform/software/#maintaining-the-application-active-until-triggered-from-the-ground","title":"Maintaining the Application Active Until Triggered from the Ground.","text":"<p>This current code will enter in checking to land logic as soon as it's launched. It's not something that's practical in the real world. </p> <p>What you would want is for this app to launch with the life cycle of the vehicle and the logic entering once a pilot, operator or logic triggers it. We can't even cover all the way to handle these three scenarios, but assuming you have a pilot and a ground application, you can leverage MOP. MOP is a feature of the MobileSDK and PayloadSDK which allows a MobileSDK application to send custom commands to a PayloadSDK application. MOP has multiple names in the DJI world. It's also referred to SDK Interconnection and Pipeline  on the Android MSDK.</p> <p>Regardless, they will allow you to build a button on the UI of a MobileSDK app that can trigger this code to enter 'checking to land' logic.</p>"},{"location":"landing-moving-platform/software/#following-the-landing-target","title":"Following the Landing Target.","text":"<p>This is another element we skipped over because there is so many ways to go over it.</p> <p>You could use a dedicated camera sensor, or the existing PayloadSDK stream.</p> <p>Regardless, you'll likely reuse the triggering we covered before to enter 'follow the target' logic which itself could trigger the 'check to land' logic itself.</p>"},{"location":"landing-moving-platform/software/#landing-risk-validation","title":"Landing Risk Validation.","text":"<p>The logic we implemented assumes that committing to a landing from any height after reading a plane of about 15\u00b0 is safe. Big assumption.</p> <p>In a more practical sense, the plane validation of the ground would depend on the characteristic of your moving platform.</p> <p>For instance, landing on a ground vehicle on a road is likely to have a much more stable plane (smaller range, slower variation). On the other hand, landing on a sea ship will dramatically vary with the weather condition, the type of ship and the operation context.  If you land on an inspection boat after an off-shore wind turbine, you're likely looking at a fairly stable motion on all aspect than if you're landing on a military ship at sea state 4.</p>"},{"location":"landing-moving-platform/software/#landing-routine","title":"Landing Routine","text":"<p>Finally, now that the logic is ready to commit, landing is a single function call behind an abstraction:</p> <pre><code>    if (!checkingToLand) {\n        // We exited the loop flagging we aren't checking to land, so we are landing.\n        std::cout &lt;&lt; \"Landing...\" &lt;&lt; std::endl;\n\n        vehicle-&gt;land();\n    }\n}\n</code></pre>"},{"location":"precision-positioning/","title":"Precision Positioning","text":"<p>In this scenario, we are going to use a SF30/D lidar sensor to build a control logic that will maintain the M350 to a distance from an obstacle.</p> <p></p> <p>We will use frontal, but being able to precisely position yourself relative to objects is a particularly important feature when navigating urban environment where GPS signal - even with RTK - may not be suitable. This is also why, you can easily adapt this project to include more than one sensor for a more accurate positioning across multiple dimensions.</p> <p>For instance, if you were to build a power washing drone out of the DJI FlyCart 30, you could have a sensor pointing down for vertical precision and forward for a frontal precision.</p> <p>Note</p> <p>Because of the nature of this stack, there are three dimensions where this scenario can easily be adapted:</p> <ol> <li>Distance vector: We are going to use distance forward to make this more interesting, but you could place the sensor facing down for altitude precise positioning</li> <li>Sensor: We are using the SF30/D for demonstration purposes. Because of its long range (200 meters - 656 feet), it's great for altitude precise positioning, but you could use any other sensor we have</li> <li>Control logic: We are going to keep it simple in the software side, but you could bake into any control loop the sensor information to do distance follow, course correction, etc.</li> </ol>"},{"location":"precision-positioning/components/","title":"Components","text":"<p>Since we're reusing the previous hardware setup, the new component list is simple:</p> Image Component Role Quantity Previous Hardware Kit Compute and sensor hold 1 SF30/D Lidar Sensor Detect the position relative to the object 1 Sensor Mount Holding the SF30/D facing forward 1 M3 x 8mm Screws Holding the sensor to the mount and the mount to the front plate. 4"},{"location":"precision-positioning/components/#sf30d","title":"SF30/D","text":"<p>We chose the SF30/D here mostly to demonstrate the flexibility of the LightWare ecosystem.  In reality, any of our sensors would do a great work, because their size, capabilities and reliability are all great for the task at hand. </p> <p>We also chose to use the USB connection for the same reasons. In the final integration of this concept into a product, you could use the direct serial connector just as well.</p>"},{"location":"precision-positioning/conclusion/","title":"Conclusion","text":"<p>Just like the landing on a moving platform scenario, we hope this scenario helps you wrap your head around how the hardware, electronics and software come together to bring new capabilities.</p> <p>As a departure from the previous scenario, we wanted to highlight how easy it is to use other product from our range, even using different mode of connections. The SF30D is an incredibly powerful sensor that's very likely under used in this context, but we hope to make the point across that all our sensors integrate seamlessly.</p> <p>We continuously work to make our products hyper accessible and easy to integrate, so you can quickly focus on the much larger part of the product that defines your unique value.</p>"},{"location":"precision-positioning/hardware/","title":"Hardware","text":""},{"location":"precision-positioning/hardware/#modification-of-the-basic-kit","title":"Modification of the Basic Kit","text":"<p>First, we need to remove some parts of the previous hardware kit.</p> <p>Namely, we won't be using the I2C bus, so we can remove all of this.</p> <p>This also allows us to reuse the mounting holes for the SF30/D.</p> <p>Note</p> <p>It is for this versatility of mounting/unmounting that heat set inserts comes handy.  As you are about to read, we can screw things directly into the plastic - even with machine screws - but mounting/unmounting would quickly wear the screws holes out without the inserts.</p> <p>We are going to use machine screws as to keep the total number of different parts lower, but ideally you would use plastic or wood screws with a coarser thread for a better grip.</p> <p></p> <p>We can now prepare the SF30/D by attaching the mounting plate to it. For this, we will use the M3x8mm screws we had, screws them directly into the plastic from the back.</p> <p> </p> <p>Next, we can attach the SF30/D mount to the front plate of the kit using M3x8mm screws again. </p> <p>Warning</p> <p>Don't overtighten the screws. The machine screws will hold fine against the layering of the 3D printed part, but within limits.</p> <p>Last, we can connect the micro USB cable that came with the sensor to the Pi, securing it the zip tie holes using the tie down that were holding the cable together in the packaging. </p> <p></p>"},{"location":"precision-positioning/hardware/#installation-on-the-aircraft","title":"Installation on the Aircraft","text":"<p>At this point, you can simply add the kit on top of the M350 and move on to the code part.</p> <p></p>"},{"location":"precision-positioning/plan/","title":"Plan","text":"<p>To position ourselves relative to an object, we need to have distance information relative to the object.  There are three dimensions to understand for a full position, but for this context, we are sticking to a single dimension.</p> <p></p> <p>The reason is simple. For the context of any mission/actions, all these dimensions aren't equally relevant to control.</p> <p>The axis that represents the most direct path between the vehicle and the object is usually the one dimension we care about most. This is compounded by the fact that the other two dimension usually align with the two dimension of the video frame from the main camera used for the pilot to navigate.</p> <p></p> <p>This is the same situation when you drive a car and don't get an accurate sense of speed looking forward, vs sideways; making the forward dimension the most important.</p> <p>This is the dimension we can and should monitor with our lidar sensor.</p>"},{"location":"precision-positioning/plan/#hardware","title":"Hardware","text":"<p>We are going to reuse the same hardware kit as described in the landing on a moving platform scenario, so you'll want to go through the components and hardware steps from that scenario if you haven't before.</p> <p>After that, we will add a mount for the SF30/D and connect it to the vehicle using USB</p> <p>Note</p> <p>We are using this approach to demonstrate the range of options in sensors and connectivity.</p> <p>You can just as easily use a LW20 and connect it to the I2C bus we setup in the previous scenario.</p>"},{"location":"precision-positioning/plan/#behavior","title":"Behavior","text":"<p>As for the behavior of the vehicle, we are going to implement a simple emergency brake that will keep us at a fixed distance.  This resembles obstacle avoidance with a simple yet important difference: In the context of collision avoidance, we want to remind the user about how much on the verge of a serious problem they are, while in our context, we are operating in a tighter context but an expected one.</p> <p>This comes with more work on the ground UX side we won't cover though beyond this note here.</p> <p>In terms of expansion, this can go as far as you'd like to - including a complete control loop to follow complex geometries.</p>"},{"location":"precision-positioning/software/","title":"Software","text":""},{"location":"precision-positioning/software/#configuration","title":"Configuration","text":"<p>If you've gone through the landing on a moving platform example, you will recognize a lot of the steps here as they are quite similar, but we provide the comprehensive content here as the software part from the landing example isn't a complete foundation for this one.</p> <p>So, before we dive into the code for the application, we need to set up all the baseline components</p>"},{"location":"precision-positioning/software/#payload-sdk-raspberry-pi","title":"Payload SDK &amp; Raspberry Pi","text":"<p>DJI covers really well how to get the Raspberry Pi setup, so follow the set up steps here</p> <p>Once you can run the sample code, we can move to the next step.</p> <p>Make sure to configure the Raspberry Pi to connect to your local Wi-Fi if available.</p> <p>Also, for convenience, make sure you have set up SSH access.</p> <p>You are now ready to dive into the code.</p>"},{"location":"precision-positioning/software/#project-code","title":"Project Code","text":"<p>Tip</p> <p>All the code for we are going to go over is available here.</p> <p>The code is in itself, functionally simple. We started by writing several classes that will abstract the sensor, the array of them and the vehicle interaction. For the vehicle and to remain true to the content set by DJI, we used the same <code>Application</code> class from their sample code.</p> <p>Note</p> <p>Remember that this project isn't production ready. If you want to deliver this functionality you'll have to polish parts of the work.</p>"},{"location":"precision-positioning/software/#connecting-to-the-aircraft","title":"Connecting to the Aircraft","text":"<p>Because the Payload SDK does the work for us, once we are set up with the hardware, the work becomes as simple as this:</p> <pre><code>#include \"lightware/SF30D.h\"\n#include \"dji/application/application.hpp\"\n\n// Some globals to make things easier\nApplication *vehicle = NULL;\nSF30D *sensor = NULL;\n\nint main(int argc, char **argv) {\n    // Create the vehicle instance to connect\n    // We are reusing the Application object from DJI's sample for clarity only.\n     vehicle = new Application(argc, argv);\n</code></pre> <p>From this point on, the vehicle object can be used to abstract vehicle functions. </p> <p>Note</p> <p>The Payload SDK uses functions. These would be accessible in the global space, but structure with objects is a neater way to organize functions.</p>"},{"location":"precision-positioning/software/#connection-to-the-sf30d","title":"Connection to the SF30/D","text":"<p>Following the logic of abstraction, we are going to create one object: <code>SF30D</code>.</p> <p><code>SF30D</code> is used to abstract a single sensor. This includes all controls and reads.</p> <p>Note</p> <p>A lot more effort can be put in these abstractions should the need come to expand on the current approach.  This class is a great place to contain it.</p> <p>First, we bring in all the headers needed for future work and then declare the class:</p> <pre><code>//\n// Created by LightWare.\n// SF30/D Interface\n//\n\n#pragma once\n\n#include &lt;iostream&gt;\n\n#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\n#include &lt;atomic&gt;\n#include &lt;thread&gt;\n#include &lt;sys/ioctl.h&gt;\n//#include &lt;asm/ioctl.h&gt;\n\n#include &lt;fcntl.h&gt;\n#include &lt;string.h&gt;\n\n#include \"lwNx.h\"\n\nclass SF30D: lwSerialPort {\n</code></pre> <p>Next, we can implement the public interface which manages the life cycle of the abstraction and protected access to private information:</p> <pre><code>public:\n\n    SF30D() { }\n\n    ~SF30D() {\n        this-&gt;disconnect();\n    }\n\nprivate:\n    std::atomic&lt;bool&gt; _initiated{false};\n    std::atomic&lt;bool&gt; _useUSB{false};\n    std::atomic&lt;bool&gt; _useSerial{false};\n\n    const char *_device = 0;\n    int _fd = -1;\n    int _bitRate = 0;\n\npublic:\n    void initForUSB(const char *device) {\n        this-&gt;_initiated.store(true, std::memory_order_relaxed);\n        this-&gt;_useUSB.store(true, std::memory_order_relaxed);\n        this-&gt;_useSerial.store(false, std::memory_order_relaxed);\n\n        this-&gt;_device = device;\n        std::cout &lt;&lt; \"Initialized for USB connection to \" &lt;&lt; device &lt;&lt; std::endl;\n    }\n\n    void initForSerial(int bitRate, const char *device) {\n        this-&gt;_initiated.store(true, std::memory_order_relaxed);\n        this-&gt;_useUSB.store(false, std::memory_order_relaxed);\n        this-&gt;_useSerial.store(true, std::memory_order_relaxed);\n\n        this-&gt;_device = device;\n        this-&gt;_bitRate = bitRate;\n        std::cout &lt;&lt; \"Initialized for Serial connection to \" &lt;&lt; device &lt;&lt; \" at \" &lt;&lt; bitRate &lt;&lt; \"bauds\" &lt;&lt; std::endl;\n    }\n\nprivate:\n    void _connectUSB() {\n\n        if (_initiated == false || _useUSB == false) {\n            std::cerr &lt;&lt; \"Please init for USB before you try to connect to USB\" &lt;&lt; std::endl;\n            return;\n        }\n\n        _fd = open(_device, O_RDWR | O_NOCTTY | O_SYNC );\n\n        if (_fd == -1) {\n            std::cerr &lt;&lt; \"USB device could not be opened\" &lt;&lt; std::endl;\n        } else {\n            std::cout &lt;&lt; \"USB device opened on FD: \" &lt;&lt; _fd &lt;&lt; std::endl;\n\n            _threadRunning.store(true, std::memory_order_relaxed);\n            _runningThread = std::thread(&amp;SF30D::loop, this);\n        }\n    }\n\n    int32_t _convertBaudRate(int32_t BitRate) {\n        switch (BitRate) {\n            case 115200: { return B115200; }\n            case 230400: { return B230400; }\n            case 460800: { return B460800; }\n            case 500000: { return B500000; }\n            case 576000: { return B576000; }\n            case 921600: { return B921600; }\n            default:\n                return B115200;\n        }\n    }\n\n    void _connectSerial() {\n\n        if (_initiated == false || _useSerial == false) {\n            std::cerr &lt;&lt; \"Please init for USB before you try to connect to USB\" &lt;&lt; std::endl;\n            return;\n        }\n\n        _fd = open((const char *) _device, O_RDWR | O_NOCTTY | O_SYNC | O_NONBLOCK);\n\n        if (_fd == -1) {\n            std::cerr &lt;&lt; \"Serial device could not be opened\" &lt;&lt; std::endl;\n        } else {\n            std::cerr &lt;&lt; \"Serial device opened on FD: \" &lt;&lt; _fd &lt;&lt; std::endl;\n\n            struct termios tty;\n            memset(&amp;tty, 0, sizeof(tty));\n            if (tcgetattr(_fd, &amp;tty) != 0) {\n                std::cerr &lt;&lt; \"Error from tcgetattr\" &lt;&lt; std::endl;\n                return;\n            }\n\n            int32_t BitRate = _convertBaudRate(_bitRate);\n\n            cfsetospeed(&amp;tty, BitRate);\n            cfsetispeed(&amp;tty, BitRate);\n\n            tty.c_cflag = (tty.c_cflag &amp; ~CSIZE) | CS8;\n            tty.c_cflag |= (CLOCAL | CREAD);\n            tty.c_cflag &amp;= ~(PARENB | PARODD);\n            tty.c_cflag |= 0;\n            tty.c_cflag &amp;= ~CSTOPB;\n            tty.c_cflag &amp;= ~CRTSCTS;\n            tty.c_iflag &amp;= ~IGNBRK;\n            tty.c_iflag &amp;= ~ICRNL;\n            tty.c_iflag &amp;= ~(IXON | IXOFF | IXANY);\n            tty.c_lflag = 0;\n            tty.c_oflag = 0;\n            tty.c_cc[VMIN] = 0;\n            tty.c_cc[VTIME] = 1;\n\n            if (tcsetattr(_fd, TCSANOW, &amp;tty) != 0) {\n                std::cerr &lt;&lt; \"Error from tcsetattr\" &lt;&lt; std::endl;\n                return;\n            }\n\n            std::cout &lt;&lt; \"Serial device connected and configured\" &lt;&lt; std::endl;\n\n            // Handshake activates the device\n            this-&gt;performHandShake();\n\n            return;\n        }\n    }\n\npublic:\n    void connect() {\n        if (this-&gt;_useUSB) {\n            this-&gt;_connectUSB();\n        } else if (this-&gt;_useSerial) {\n            this-&gt;_connectSerial();\n        } else {\n            std::cerr &lt;&lt; \"Wrong initiation state, please init this object before connecting\";\n        }\n    }\n\n    void disconnect() {\n        _threadRunning.store(false, std::memory_order_relaxed);\n        if (_fd &gt;= 0) {\n            close(_fd);\n        }\n        _fd = -1;\n    }\n\n    float latestDistance() {\n        return this-&gt;_latestDistance.load(std::memory_order_relaxed);\n    }\n</code></pre> <p>Note</p> <p>We have implemented a USB and a Serial mode. These two modes use different ways to achieve the same thing. The Serial link uses the binary protocol LWNX which allows for more complete control over the sensor.</p> <p>For more info, check the public documentation.</p> <p>Warning</p> <p>If you've gone through the LW20 sample before, pay attention to the return type for distance which are now <code>float</code></p> <p>Last, we do the private implementation which covers the internal loop running in a background thread to read the data from the sensor, the binary protocol messages and the protected variables.</p> <pre><code>private:\n    std::atomic&lt;bool&gt; _threadRunning{false};\n    std::thread _runningThread;\n\n    int writeData(uint8_t *Buffer, int32_t BufferSize) {\n        if (_fd &lt; 0) {\n            std::cout &lt;&lt; \"Can't write to null coms\" &lt;&lt; std::endl;\n            return -1;\n        }\n\n        int writtenBytes = write(_fd, Buffer, BufferSize);\n\n        if (writtenBytes != BufferSize)\n        {\n            // std::cout &lt;&lt; \"Could not send all bytes!\" &lt;&lt; std::endl;\n            return -1;\n        }\n\n        //  std::cout &lt;&lt; \"Sent \" &lt;&lt; BufferSize &lt;&lt; \" bytes\" &lt;&lt; std::endl\n        return writtenBytes;\n    }\n\n    int32_t readData(uint8_t *Buffer, int32_t BufferSize) {\n        if (_fd &lt; 0) {\n            std::cout &lt;&lt; \"Can't read from null coms\" &lt;&lt; std::endl;\n            return -1;\n        }\n\n        errno = 0;\n        int readBytes = read(_fd, Buffer, BufferSize);\n\n        return readBytes;\n    }\n\n\n\n    // Data received from the sensor.\n\n    float _distance = 0.0; // in m\n    unsigned int _strength = 0; // in percentage\n    unsigned int _temperature = 0; // in degrees\n\n    std::atomic&lt;float&gt; _latestDistance{0.0}; // in m\n\n\n    void _getNextUSBReading() {\n        char line[64];\n        int lineSize = 0;\n\n        while (true) {\n            char recvData;\n            if (this-&gt;readData((uint8_t*)&amp;recvData, 1) == 1) {\n                if (recvData == '\\n') {\n                    line[lineSize] = 0;\n                    this-&gt;_distance = atof(line);\n                    return;\n                } else if (isdigit(recvData) || recvData == '.') {\n                    line[lineSize++] = recvData;\n\n                    if (lineSize == sizeof line) {\n                        lineSize = 0;\n                    }\n                }\n            }\n        }\n    }\n\n    uint16_t readInt16(uint8_t *Buffer, uint32_t Offset) {\n        uint16_t result;\n        result = (Buffer[Offset + 0] &lt;&lt; 0) | (Buffer[Offset + 1] &lt;&lt; 8);\n        return result;\n    }\n\n    void _getNextSerialReading() {\n\n        while (true) {\n            lwResponsePacket response;\n\n            if (lwnxRecvPacket(this, 44, &amp;response, 1000)) {\n                uint16_t firstReturnRaw = readInt16(response.data, 4);\n                uint16_t firstReturnFiltered = readInt16(response.data, 6);\n                uint16_t firstReturnStrength = readInt16(response.data, 8);\n\n                uint16_t lastReturnRaw = readInt16(response.data, 10);\n                uint16_t lastReturnFiltered = readInt16(response.data, 12);\n                uint16_t lastReturnStrength = readInt16(response.data, 14);\n\n                uint16_t backgroundNoise = readInt16(response.data, 16);\n                uint16_t temperature = readInt16(response.data, 18) / 100;\n\n                _distance = static_cast&lt;float&gt;(firstReturnFiltered)/100;\n                _strength = firstReturnStrength;\n                _temperature = temperature;\n                return;\n            }\n        }\n    }\n\n    void getNextReading() {\n        if (this-&gt;_useUSB) {\n            this-&gt;_getNextUSBReading();\n        } else if (this-&gt;_useSerial) {\n            this-&gt;_getNextSerialReading();\n        } else {\n            std::cerr &lt;&lt; \"Wrong initiation state, please init this object before connecting\";\n        }\n    }\n\n\n    // Loop running in background thread.\n    void loop() {\n        while (_threadRunning.load(std::memory_order_relaxed))  {\n            this-&gt;getNextReading();\n            std::cout &lt;&lt; \"[\" &lt;&lt; _device &lt;&lt; \"] Distance: \" &lt;&lt; _distance &lt;&lt; \" m\" &lt;&lt; std::endl;\n\n            _latestDistance.store(_distance, std::memory_order_relaxed);\n        }\n    }\n\n\npublic:\n    // Serial Commands\n\n    std::string getModelName() {\n        if (!_initiated || !_useSerial) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return \"\";\n        }\n\n        char modelName[16]{};\n        //        if (!lwnxCmdReadString(this, LWNXProductNameCmdID, modelName)) {\n        //            std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n        //      return \"\";\n        //        }\n\n        while(lwnxCmdReadString(this, LWNXProductNameCmdID, modelName) == false) {\n            usleep(50);\n        }\n\n\n        printf(\"Model: %.16s\\n\", modelName);\n        return std::string(modelName);\n    }\n\n    uint32_t getHardwareVersion() {\n        if (_initiated == false || _useSerial == false) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return 0;\n        }\n\n        // Read the hardware version. (Command 1: Hardware version)\n        uint32_t hardwareVersion = 0;\n        // if (!lwnxCmdReadUInt32(this, 1, &amp;hardwareVersion)) {\n        //     std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n        //     return 0;\n        // }\n\n        while (lwnxCmdReadUInt32(this, 1, &amp;hardwareVersion) == false) {\n            usleep(50);\n        }\n\n\n        printf(\"Hardware: %d\\n\", hardwareVersion);\n        return hardwareVersion;\n    }\n\n    uint32_t  getFirmwareVersion(){\n        if (_initiated == false || _useSerial == false) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return 0;\n        }\n\n        // Read the firmware version. (Command 2: Firmware version)\n        uint32_t firmwareVersion = 0;\n        // if (!lwnxCmdReadUInt32(this, 2, &amp;firmwareVersion)) {\n        //     std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n        //     return 0;\n        // }\n        while (lwnxCmdReadUInt32(this, 2, &amp;firmwareVersion) == false) {\n            usleep(50);\n        }\n\n        char firmwareVersionStr[16];\n        lwnxConvertFirmwareVersionToStr(firmwareVersion, firmwareVersionStr);\n        printf(\"Firmware: %.16s (%d)\\n\", firmwareVersionStr, firmwareVersion);\n        return firmwareVersion;\n    }\n\n    std::string getSerialNumber() {\n        if (!_initiated || !_useSerial) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return \"\";\n        }\n\n        char serialNumber[16]{};\n        // if (!lwnxCmdReadString(this, 3, serialNumber)) {\n        //     std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n        //     return \"\";\n        // }\n        while (!lwnxCmdReadString(this, 3, serialNumber) == false) {\n            usleep(50);\n        }\n\n        printf(\"Serial: %.16s\\n\", serialNumber);\n        return std::string(serialNumber, 16);\n    }\n\n    void performHandShake() {\n        this-&gt;getModelName();\n        this-&gt;getHardwareVersion();\n        this-&gt;getFirmwareVersion();\n        this-&gt;getSerialNumber();\n        std::cout &lt;&lt; \"Handshake Complete\" &lt;&lt; std::endl;\n    }\n\n    void setUpdateRate(uint8_t rate) {\n        if (_initiated == false || _useSerial == false) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return;\n        }\n\n        // Set the output rate to 78 readings per second. (Command 76: Update rate)\n        //     if (!lwnxCmdWriteUInt8(this, LWNXUpdateRateCmdID, rate)) {\n        //         std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n        //     }\n\n        while (lwnxCmdWriteUInt8(this, LWNXUpdateRateCmdID, rate) == false) {\n            usleep(50);\n        }\n\n        std::cout &lt;&lt; \"Rate Updated\" &lt;&lt; std::endl;\n    }\n\n    void setDistanceOutputConfig(uint32_t config) {\n        if (_initiated == false || _useSerial == false) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return;\n        }\n\n        // Set distance output to include all information (0xFFFFFFFF): (Command 29: Distance output)\n        //     if (!lwnxCmdWriteUInt32(this, LWNXDistanceOutputCmdID, config)) {\n        //         std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n        //     }\n        while (lwnxCmdWriteUInt32(this, LWNXDistanceOutputCmdID, config) == false) {\n            usleep(50);\n        }\n\n        std::cout &lt;&lt; \"Distance Output Config Set\" &lt;&lt; std::endl;\n    }\n\n    void enableStreaming() {\n        if (_initiated == false || _useSerial == false) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return;\n        }\n\n        // Enable streaming of point data. (Command 30: Stream)\n        // if (!lwnxCmdWriteUInt32(this, LWNXStreamCmdID, 5)) {\n        //     std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n        //     return;\n        // }\n\n        while (lwnxCmdWriteUInt32(this, LWNXStreamCmdID, 5) == false) {\n            usleep(50);\n        }\n\n        // Loop start fetching info\n        _threadRunning.store(true, std::memory_order_relaxed);\n        _runningThread = std::thread(&amp;SF30D::loop, this);\n\n        std::cout &lt;&lt; \"Streaming Started\" &lt;&lt; std::endl;\n    }\n\n    void disableStreaming() {\n        if (_initiated == false || _useSerial == false) {\n            std::cerr &lt;&lt; \"Can't call serial command. Please init for serial first\" &lt;&lt; std::endl;\n            return;\n        }\n\n        // Disable streaming of point data. (Command 30: Stream)\n        if (!lwnxCmdWriteUInt32(this, LWNXStreamCmdID, 0)) {\n            std::cerr &lt;&lt; \"No Response to command\" &lt;&lt; std::endl;\n            return;\n        }\n\n        // Killing the read thread\n        _threadRunning.store(false, std::memory_order_relaxed);\n    }\n};\n</code></pre> <p>Note</p> <p>This abstraction relies on side files coming from our sample code library. For the full access to the sample code, please visit our GitHub</p> <p>Now that we have an abstraction for the vehicle and the sensor, it's time to tie it all up together.</p>"},{"location":"precision-positioning/software/#distance-detection-logic","title":"Distance Detection Logic","text":"<p>As the purpose of this tutorial is to cover how to leverage the sensors, we are taking the most simplistic approach to solving this problem.  This means there is obviously a lot of room for improvements towards delivering a resilient and production ready solution; or even to take this to more specific expected behaviors. We will cover a few next steps should you want to take it further after we covered the simple solution we offer.</p> <p>Back to the <code>main.cpp</code> file in the <code>main</code> function, after we created the abstraction for the vehicle, we create the abstraction for the sensor and connect it.</p> <p>After this, we assume we are in checking distance logic. We loop until the condition met is hit, then we exit the loop and stop the vehicle at this distance:</p> <pre><code>int main(int argc, char **argv) {\n    // Create the vehicle instance to connect\n    // We are reusing the Application object from DJI's sample for clarity only.\n     vehicle = new Application(argc, argv);\n\n    sensor = new SF30D();\n    const char *device = \"/dev/my_device\"; // Depends on how the laser is connected to your computer.\n    sensor-&gt;initForSerial(115200, device);\n    sensor-&gt;connect();\n\n    // set the frequency rate\n    sensor-&gt;setUpdateRate(LWNXUpdateRateParam78);\n    // setting all params for the output aka 0xFFFFFFFF\n    sensor-&gt;setDistanceOutputConfig(LWNXDistanceOutputParamFirstReturnRaw |\n                                      LWNXDistanceOutputParamFirstReturnFilter |\n                                      LWNXDistanceOutputParamFirstReturnStrength |\n                                      LWNXDistanceOutputParamLastReturnRaw |\n                                      LWNXDistanceOutputParamLastReturnFilter |\n                                      LWNXDistanceOutputParamLastReturnStrength |\n                                      LWNXDistanceOutputParamBackgroundNoise |\n                                      LWNXDistanceOutputParamTemperature );\n    sensor-&gt;enableStreaming();\n\n    // Check loop\n     bool active = true;\n    float closeEnough = 0.5; // in m; 50cm\n\n    while (active) {\n        float currentDistance = sensor-&gt;latestDistance();\n\n        // Condition to determine a landing opportunity.\n        if (currentDistance &lt;= closeEnough &amp;&amp; currentDistance &gt; 0 &amp;&amp; currentDistance &lt; 250) { // 0 and 250 are false reads\n            // We exited the loop flagging we aren't checking to land, so we are landing.\n            std::cout &lt;&lt; \"Stopping Vehicle...\" &lt;&lt; std::endl;\n\n            vehicle-&gt;emergencyBreak(); // Stop the vehicle right now.\n        }\n        usleep(250);\n    }\n}\n</code></pre> <p>As you can see this is incredibly simple in this form so here are extra next steps for your consideration:</p>"},{"location":"precision-positioning/software/#application-lifecycle-control-from-the-ground","title":"Application lifecycle control from the Ground.","text":"<p>This current code will enter in checking the distance logic as soon as it's launched. It's not something that's practical in the real world. </p> <p>What you would want is for this app to launch with the life cycle of the vehicle and the logic entering once a pilot, operator or logic triggers it. We can't even cover all the way to handle these three scenarios, but assuming you have a pilot and a ground application, you can leverage MOP. MOP is a feature of the MobileSDK and PayloadSDK which allows a MobileSDK application to send custom commands to a PayloadSDK application. MOP has multiple names in the DJI world. It's also referred to SDK Interconnection and Pipeline  on the Android MSDK.</p> <p>Regardless, they will allow you to build a button on the UI of a MobileSDK app that can trigger this code to enter 'checking the distance' logic.</p> <p>MOP can also be used to bring back to the UI the exact distance reading should you want to. It can also be leveraged to configure the distance you would want to stay at, or a range of distances.  It can also allow for advanced behaviors - including fully autonomous behavior from the vehicle with a control loop against the sensor read.</p> <p>Last, if you bring the sensor value to the ground, you can build this autonomy from the MobileSDK side - you will have to account for the extra latency that exist being behind the radio.</p>"},{"location":"precision-positioning/software/#expanding-the-context-of-operation","title":"Expanding the Context of Operation","text":"<p>Without knowing exactly what the precision of the distance may be used for, it's just too much speculation as to how to handle the rest of the behavior, but let's take a look at the suggestion we made with the power washing drone.</p> <p>In this context, we would be wanting to stay at a distance against a building that is efficient for the washing, accounting for movement deviation.  In short, we would want to stay between two distances representing the optimal range of operation.</p> <p>Also, we could use sudden changes of distance read as a way of detecting building edges. You could even add a secondary lidar to get two points for better edge detections.</p> <p>Both of these capabilities would be simply expended by added a second value for the distance (to create a range) and incorporating more logic to the execution.</p> <p>This logic could go all the way to be a complete 'wash the line' behavior that incorporate the lidar into its control loop to control the movement of the vehicle while the behavior is triggered from the ground.</p> <p>This becomes a different focus altogether, but we know our sensor will help you get the job done.</p>"},{"location":"spoi/","title":"M350 Landing on a Moving Platform","text":"<p>In this scenario, we are going to walk through the steps to add a capability to the DJI M350 which isn't present on the vehicle by default: The ability to land on a moving platform.</p> <p>The scope of this tutorial is to focus on how to use our products, so we will skim through the other components and only cover the extent necessary for the whole solution to be reproduceable.</p>"},{"location":"spoi/#plan","title":"Plan","text":"<p>In order to land a vehicle on a moving platform, we need to first characterize the situation. In this case, moving platform implies a vehicle which landing platform will be affected by it motion.  There is obviously the translational effect, but also the three-dimensional effect on the plate which will limit the window of opportunity for the vehicle to commit to a landing.</p> <p>In the case of boat, the deck of boat will tilt in two axis in a way that could jeopardize the vehicle's safety.</p> <p>To understand when the window of opportunity presents itself, we need to be able to observe in real time the plane represented by the deck and identify a moment of least-risk and commit with understanding of the motion capabilities of the vehicle.</p> <p>INSERT DIAGRAM HERE</p> <p>Now that we have a decent idea of how we will approach this problem, we can start planning for the components at play and their roles.</p>"},{"location":"spoi/components/","title":"Components","text":""},{"location":"spoi/components/#components","title":"Components","text":"<p>To achieve this, we will leverage four LW20/C lidar sensors. These will be used to create a real-time, high frequency plane detection to be incorporated in a custom landing routine running on an onboard computer attached to the M350.</p> Component Role DJI M350 Main Vehicle LW20C Landing Deck Plane Detection Raspberry Pi 5 Onboard Compute DJI E-Port Kit PSDK Interface"},{"location":"spoi/hardware/","title":"Hardware","text":""},{"location":"spoi/hardware/#hardware","title":"Hardware","text":""},{"location":"spoi/plan/","title":"M350 Landing on a Moving Platform","text":"<p>In this scenario, we are going to walk through the steps to add a capability to the DJI M350 which isn't present on the vehicle by default: The ability to land on a moving platform.</p> <p>The scope of this tutorial is to focus on how to use our products, so we will skim through the other components and only cover the extent necessary for the whole solution to be reproduceable.</p>"},{"location":"spoi/plan/#plan","title":"Plan","text":"<p>In order to land a vehicle on a moving platform, we need to first characterize the situation. In this case, moving platform implies a vehicle which landing platform will be affected by it motion.  There is obviously the translational effect, but also the three-dimensional effect on the plate which will limit the window of opportunity for the vehicle to commit to a landing.</p> <p>In the case of boat, the deck of boat will tilt in two axis in a way that could jeopardize the vehicle's safety.</p> <p>To understand when the window of opportunity presents itself, we need to be able to observe in real time the plane represented by the deck and identify a moment of least-risk and commit with understanding of the motion capabilities of the vehicle.</p> <p>INSERT DIAGRAM HERE</p> <p>Now that we have a decent idea of how we will approach this problem, we can start planning for the components at play and their roles.</p>"},{"location":"spoi/software/","title":"Software","text":""},{"location":"spoi/software/#software","title":"Software","text":""}]}